{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 2. Проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имя, Фамилия: Игнат Сальников\n",
    "\n",
    "группа: 221\n",
    "\n",
    "**Оценка(для проверяющего):** 0 из 32\n",
    "\n",
    "**Дедлайн:** 24 ноября 23:59 (решение нужно сдать в энитаск)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение. Несколько слов о шахматах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом домашнем задании вам будет представлен набор данных связанных с шахматами. Напомним, что шахматная партия может заканчиваться одним из трёх исходов:\n",
    "- Победа белых (записывается как 1-0)\n",
    "- Победа чёрных (записывается как 0-1)\n",
    "- Ничейный исход (записывается как 1/2-1/2)\n",
    "\n",
    "Также, в соревновательных шахматах есть временной контроль: партии делятся на несколько категорий, в зависимости от того, сколько времени оппонненты имеют на размышления:\n",
    "- Блиц (до 10 минут на все ходы, возможно с добавлением времени после каждого хода)\n",
    "- Рапид (от 10 до 30 минут на все ходы, возможно с добавлением времени после каждого хода)\n",
    "- Классические или медленные шахматы (от 30 минут на все ходы, часто с добавлением времени после 40 и 60 ходов)\n",
    "\n",
    "Для того чтобы как-то классифицировать силу игроков, была введена рейтинговая система ELO, на основании которой игрокам присуждается ранг (например международный мастер или гроссмейстер) и формируются турниры. Отметим что рейтинг ELO меняется, в зависимости от того, в каком формате временного контроля игрок участвует (т.е. у одного человека разный рейтинг для блица, рапида и классических шахмат). \n",
    "\n",
    "В этом датасете собраны основные данные об шахматных партиях, сыгранными за период с 1980 по 2021 года.\n",
    "- Представлены партии всех трех форматов, формат партии указан в поле ``control``\n",
    "- Исход партии представлен в поле ``result``\n",
    "- Рейтинги оппонентов записаны в полях ``elo_white`` и ``elo_black`` для рейтинга играющих за белых и за черных соответственно.  \n",
    "    - Поле ``elo_average`` содержит среднее значение ``elo_white`` и ``elo_black`` -- _усредненный рейтинг (оппонентов)_. \n",
    "    - Поле ``elo_difference`` содержит в себе значение ``elo_white - elo_black``. \n",
    "- Поле ``opening`` содержит одно из пяти значений ``'A', 'B', 'C', 'D', 'E'``, которое кодирует информацию о нескольких первых ходах в партии (см. задачу 3 для деталей). \n",
    "- В поле ``length`` записано число сделанных ходов в партии. Обратите внимание, что ход -- это движение одной фигуры со стороны белых **и** движение одной фигуры со стороны чёрных, т.е. за один ход и белые и черные совершают по действию.\n",
    "- Поля ``date`` и ``site`` содержат информацию о том, в каком году была сыграна партия и место её проведения соответственно. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор данных (2 балла)\n",
    "В этой секции вам предлагается познакомиться с данными. Посмотрите на три разных формата временного контроля. Сравните как в каждом из них \n",
    "- Распределены исходы партий (победа белых/победа чёрных/ничья)\n",
    "- Распределены усреднённые рейтинги оппонентов партий \n",
    "- Распределены длительности партий \n",
    "\n",
    "**Бонус (max 3 дополнительных балла)** При желании, можно также посмотреть другие вещи --- например как менялось количество партий по декадам или пятилеткам. Попробуйте обнаружить и _объяснить_ интересные и статистически значимые феномены.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:39:23.413475Z",
     "iopub.status.busy": "2024-11-03T12:39:23.412551Z",
     "iopub.status.idle": "2024-11-03T12:39:23.419191Z",
     "shell.execute_reply": "2024-11-03T12:39:23.417979Z",
     "shell.execute_reply.started": "2024-11-03T12:39:23.413409Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.precision', 5)\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:39:23.647649Z",
     "iopub.status.busy": "2024-11-03T12:39:23.647239Z",
     "iopub.status.idle": "2024-11-03T12:39:34.869185Z",
     "shell.execute_reply": "2024-11-03T12:39:34.868058Z",
     "shell.execute_reply.started": "2024-11-03T12:39:23.647612Z"
    }
   },
   "outputs": [],
   "source": [
    "games_df = pd.read_csv(\"data/games.csv\")\n",
    "games_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:39:34.871929Z",
     "iopub.status.busy": "2024-11-03T12:39:34.871431Z",
     "iopub.status.idle": "2024-11-03T12:39:34.888462Z",
     "shell.execute_reply": "2024-11-03T12:39:34.887096Z",
     "shell.execute_reply.started": "2024-11-03T12:39:34.871879Z"
    }
   },
   "outputs": [],
   "source": [
    "games_df.info(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_distrib = games_df.groupby(['control', 'result']).size().reset_index(name='count')\n",
    "\n",
    "total_per_control = result_distrib.groupby('control')['count'].transform('sum')\n",
    "result_distrib['distrib'] = (result_distrib['count'] / total_per_control) * 100\n",
    "\n",
    "px.bar(\n",
    "    result_distrib, \n",
    "    x='control', y='distrib', color='result', \n",
    "    title=\"Distribution of game\\'s result by format\",\n",
    "    barmode='group', text='distrib'\n",
    ").update_traces(\n",
    "    texttemplate='%{text:.1f}%', textposition='outside'\n",
    ").update_layout(\n",
    "    yaxis=dict(ticksuffix='%')\n",
    ").show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в разных временных форматах совершенно разное распределение исходов партий. Это указывает нам на то что надо завести три различных набора данных и работать с каждым по отдельности:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте для каждого из контролей распределение усредненного рейтинга партий и длин партий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(\n",
    "    games_df, \n",
    "    x='elo_average', color='control', facet_row='control', orientation='h',\n",
    "    box=True,\n",
    "    title=\"Distribution of game\\'s averaged elo by format\"\n",
    ").update_yaxes(matches=None).show(renderer='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    games_df, \n",
    "    x='elo_average', color='control', facet_row='control',\n",
    "    title=\"Distribution of game\\'s averaged elo by format\",\n",
    "    opacity=0.75,\n",
    "    nbins=500,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    range_x=[600, None]\n",
    ").update_yaxes(\n",
    "    matches=None\n",
    ").show(renderer='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.violin(\n",
    "    games_df, \n",
    "    x='length', color='control', facet_row='control', orientation='h',\n",
    "    box=True,\n",
    "    title=\"Distribution of game\\'s lengths by format\",\n",
    ").update_yaxes(matches=None).show(renderer='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:06.407840Z",
     "iopub.status.busy": "2024-11-03T12:40:06.407355Z",
     "iopub.status.idle": "2024-11-03T12:40:13.210056Z",
     "shell.execute_reply": "2024-11-03T12:40:13.208818Z",
     "shell.execute_reply.started": "2024-11-03T12:40:06.407780Z"
    }
   },
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    games_df, \n",
    "    x='length', color='control', facet_row='control',\n",
    "    title=\"Distribution of game\\'s lengths by format\",\n",
    "    opacity=0.75,\n",
    "    nbins=500,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    range_x=[0, 300]\n",
    ").update_yaxes(matches=None).show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус (должно было быть больше, но я забил)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df[\"skill_lavel\"] = np.where(games_df[\"elo_average\"] > 1500, \"high\", \"low\")\n",
    "\n",
    "px.histogram(\n",
    "    games_df, \n",
    "    x='date', color='control', facet_row='control',\n",
    "    facet_col='skill_lavel', facet_col_spacing=0.05,\n",
    "    title=\"Number of games in time by format and skill lavel\",\n",
    "    opacity=0.75,\n",
    "    width=800,\n",
    "    height=800,\n",
    "    nbins=16 * 4\n",
    ").update_yaxes(\n",
    "    matches=None\n",
    ").show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество партий стабильно росто. Бум в популярности блица и рапида случился примерно с начала ковида. При этом, как мне кажется, популярны именно быстрые форматы так как они более зрелищные. Пики количества игр на низком уровне я бы отнес к проведению каких-нибудь крупных любительских турниров или может быть появлению онлайн шахмат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-30T19:32:37.350608Z",
     "iopub.status.busy": "2024-10-30T19:32:37.350060Z",
     "iopub.status.idle": "2024-10-30T19:32:37.394196Z",
     "shell.execute_reply": "2024-10-30T19:32:37.393018Z",
     "shell.execute_reply.started": "2024-10-30T19:32:37.350501Z"
    }
   },
   "source": [
    "## Разминка. Проверка гипотез о средних (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взгляд в прошлое. Рейтинг игр в Праге. (2 балла)\n",
    "Пусть $X_1, \\ldots, X_n \\overset{\\text{i.i.d}}{\\sim} X$ --- выборка из некоторого распределения. Вспомните как строится асимптотический доверительный интервал для $\\mathbb{E}[X]$, и, используя асимптотический z-test проверьте на уровне значимости $\\alpha = 0.05$ гипотезу о том что математическое ожидание рейтинга партии равно 2389:\n",
    "$$\n",
    "    H_0 : \\mathbb{E}[X] = 2389 \\\\\n",
    "    H_1 : \\mathbb{E}[X] \\neq 2389\n",
    "$$\n",
    "для игр, сыгранных в Праге за период 1980-1989 г."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При справедливости $H_0$ имеем:\n",
    "\n",
    "$$z = \\frac{\\bar{X} - 2389}{\\hat{\\sigma} / \\sqrt{n}}; \\qquad z \\sim_{n \\to \\infty} \\mathcal{N}(0, 1)$$\n",
    "\n",
    "Для двухстороннего теста смотрим лежит ли $z$ в интервале $(z_{\\alpha/2}, z_{1 - \\alpha/2})$ и если нет, то отвергаем гипотезу. Для правосторонего отвергаем если $z > z_{1 - \\alpha}$, а для левостороннего если  $z < z_{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:13.212605Z",
     "iopub.status.busy": "2024-11-03T12:40:13.212115Z",
     "iopub.status.idle": "2024-11-03T12:40:13.224313Z",
     "shell.execute_reply": "2024-11-03T12:40:13.223219Z",
     "shell.execute_reply.started": "2024-11-03T12:40:13.212551Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.typing import ArrayLike\n",
    "from typing import Tuple, Optional, Literal\n",
    "\n",
    "hypothesis_side = Literal[\"both\", \"left\", \"right\"]\n",
    "\n",
    "\n",
    "class StatTestResult:\n",
    "    \"\"\"\n",
    "    Wrapper that carries information about performed statistical test. \n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    statistics : float\n",
    "        value of the test's statistics.\n",
    "    p_value : float\n",
    "        obtained p-value for the test's statistics.\n",
    "    significance : float\n",
    "        significance level for the performed test\n",
    "    critical_value : float\n",
    "        critical value of the test's statistics for the given significance level \n",
    "    test_name : str\n",
    "        name of the test\n",
    "    null_name: str\n",
    "        formulation of the null hypothesis\n",
    "    alternative_name : str\n",
    "        formulation of the alternative hypothesis\n",
    "    verdict: \n",
    "        test's verdict\n",
    "    \"\"\"\n",
    "    def __init__(self, statistics : float, p_value : float, significance : float, critical_value : float,\\\n",
    "                        test_name : str, null_name : str, alternative_name : str):\n",
    "        self.statistics = statistics\n",
    "        self.p_value = p_value\n",
    "        self.significance = significance\n",
    "        self.critical_value = critical_value\n",
    "        self.name = test_name\n",
    "        self.null = null_name\n",
    "        self.alternative = alternative_name\n",
    "        \n",
    "        if self.p_value < self.significance:\n",
    "            self.verdict = f\"Reject H0 at significance level {significance}\"\n",
    "        else:\n",
    "            self.verdict = f\"Accept H0 at significance level {significance}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"\"\"\n",
    "        {self.name}. \n",
    "        H0: {self.null}\n",
    "        H1: {self.alternative}\n",
    "        ===================================\n",
    "        Statistics value: {self.statistics}. Critical value: {self.critical_value}\n",
    "        P-value: {self.p_value}, \n",
    "        Verdict: {self.verdict}\n",
    "        \"\"\"\n",
    "    def __str__(self):\n",
    "        return f\"Statistics: {self.statistics}, P-value: {self.p_value}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:13.226693Z",
     "iopub.status.busy": "2024-11-03T12:40:13.226245Z",
     "iopub.status.idle": "2024-11-03T12:40:13.240006Z",
     "shell.execute_reply": "2024-11-03T12:40:13.238730Z",
     "shell.execute_reply.started": "2024-11-03T12:40:13.226652Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "\n",
    "def z_test_one_sample(sample : ArrayLike, null_mean : float,\n",
    "                      significance : float = 0.05, tail : hypothesis_side = 'both') -> StatTestResult:\n",
    "    \"\"\"\n",
    "        Performs asymptotic z-test for the one sample\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        sample : ArrayLike\n",
    "            sample on which z-test will be performed \n",
    "        null_mean : float\n",
    "            value of mean under null hypothesis.\n",
    "        significance : float\n",
    "            significance level for the performed test\n",
    "        tail : Literal[\"both\", \"left\", \"right\"]\n",
    "            alternative side\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        res : StatTestResult\n",
    "            An object containing infomration about test results\n",
    "    \"\"\"\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_std = np.std(sample, ddof=1)\n",
    "    n = len(sample)\n",
    "    \n",
    "    z_statistic = np.sqrt(n) * (sample_mean - null_mean) / sample_std \n",
    "    \n",
    "    if tail == 'both':\n",
    "        p_value = 2 * sps.norm.sf(np.abs(z_statistic))\n",
    "    elif tail == 'right':\n",
    "        p_value = sps.norm.sf(z_statistic)\n",
    "    elif tail == 'left':\n",
    "        p_value = sps.norm.cdf(z_statistic)\n",
    "        \n",
    "        \n",
    "    critical_value = sps.norm.ppf(1 - significance / 2) if tail == 'both' \\\n",
    "        else (sps.norm.ppf(1 - significance) if tail == 'right' else sps.norm.ppf(significance))\n",
    "    \n",
    "    result = StatTestResult(\n",
    "        statistics=z_statistic,\n",
    "        p_value=p_value,\n",
    "        significance=significance,\n",
    "        critical_value=critical_value,\n",
    "        test_name=\"z-test\",\n",
    "        null_name=f\"mu = {null_mean}\",\n",
    "        alternative_name=f\"mu {'!=' if tail == 'both' else ('>' if tail == 'right' else '<')} {null_mean}\"\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:13.241936Z",
     "iopub.status.busy": "2024-11-03T12:40:13.241567Z",
     "iopub.status.idle": "2024-11-03T12:40:14.321027Z",
     "shell.execute_reply": "2024-11-03T12:40:14.319822Z",
     "shell.execute_reply.started": "2024-11-03T12:40:13.241899Z"
    }
   },
   "outputs": [],
   "source": [
    "data = games_df[(games_df['site'] == 'Prague') & (games_df['date'] >= 1980) \\\n",
    "                & (games_df['date'] <= 1989)]['elo_average']\n",
    "\n",
    "z_test_one_sample(data, 2389, tail='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение**: Не отвергаем гипотезу, что тут еще сказать "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Назад в будущее. Рейтинг игр в Москве. (3 балла)\n",
    "После того как вы проверили эту гипотезу, проверьте гипотезу о том, что средний рейтинг классических партий проводимых в Москве в 2010-2019 годах выше, чем рейтинг в 2000-2009 годах. Вспомните как устроен z-тест для двух выборок и \n",
    "1. сформулируйте нулевую гипотезу и альтернативу;\n",
    "2. укажите статистику и её распределение при верной нулевой гипотезе;\n",
    "3. реализуйте тест и проверьте гипотезу на уровне значимости 0.05;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    H_0 : \\mathbb{E}[X] = \\mathbb{E}[Y] \\\\\n",
    "    H_1 : \\mathbb{E}[X] < \\mathbb{E}[Y]\n",
    "$$\n",
    "\n",
    "По сути мы проверяем гипотезу о том не хуже ли рейтинг в 2010-2019 годах, но как мы увидим ниже этого достаточно.\n",
    "\n",
    "При справедливости $H_0$ и независимости $X$ и $Y$ (как у нас) имеем:\n",
    "\n",
    "$$z = \\dfrac{\\bar{X} - \\bar{Y}}{\\sqrt{\\hat{\\sigma}_1^2/n_1 + \\hat{\\sigma}_2^2/{n_2}}}; \\qquad z \\sim_{n \\to \\infty} \\mathcal{N}(0, 1)$$\n",
    "\n",
    "\n",
    "Для двухстороннего теста смотрим лежит ли $z$ в интервале $(z_{\\alpha/2}, z_{1 - \\alpha/2})$ и если нет, то отвергаем гипотезу. Для правосторонего отвергаем если $z > z_{1 - \\alpha}$, а для левостороннего если  $z < z_{\\alpha}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:14.326650Z",
     "iopub.status.busy": "2024-11-03T12:40:14.326239Z",
     "iopub.status.idle": "2024-11-03T12:40:14.341035Z",
     "shell.execute_reply": "2024-11-03T12:40:14.339868Z",
     "shell.execute_reply.started": "2024-11-03T12:40:14.326609Z"
    }
   },
   "outputs": [],
   "source": [
    "def z_test_two_sample(sample_x : ArrayLike, sample_y : ArrayLike, null_mean_diff : float = 0,\n",
    "                      significance : float = 0.05, tail : hypothesis_side = 'both') -> StatTestResult:\n",
    "    \"\"\"\n",
    "        Performs asymptotic z-test for the two samples\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        sample_x : ArrayLike\n",
    "            first sample for the z-test \n",
    "        sample_y : ArrayLike\n",
    "            second sample for the z-test\n",
    "        null_mean_diff : float\n",
    "            differences of means under null hypothesis.\n",
    "        significance : float\n",
    "            significance level for the performed test\n",
    "        tail : Literal[\"both\", \"left\", \"right\"]\n",
    "            alternative side\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        res : StatTestResult\n",
    "            An object containing infomration about test results\n",
    "    \"\"\"\n",
    "    \n",
    "    sample_mean_x = np.mean(sample_x)\n",
    "    sample_mean_y = np.mean(sample_y)\n",
    "    \n",
    "    n_x = len(sample_x)\n",
    "    n_y = len(sample_y)\n",
    "    \n",
    "    std_of_sample = np.sqrt(np.std(sample_x, ddof=1)**2 / n_x + np.std(sample_y, ddof=1)**2 / n_y)\n",
    "    \n",
    "    z_statistic = (sample_mean_x - sample_mean_y - null_mean_diff) / std_of_sample \n",
    "    \n",
    "    if tail == 'both':\n",
    "        p_value = 2 * sps.norm.sf(np.abs(z_statistic))\n",
    "    elif tail == 'right':\n",
    "        p_value = sps.norm.sf(z_statistic)\n",
    "    elif tail == 'left':\n",
    "        p_value = sps.norm.cdf(z_statistic)\n",
    "        \n",
    "    critical_value = sps.norm.ppf(1 - significance / 2) if tail == 'both' \\\n",
    "        else (sps.norm.ppf(1 - significance) if tail == 'right' else sps.norm.ppf(significance))\n",
    "    \n",
    "    result = StatTestResult(\n",
    "        statistics=z_statistic,\n",
    "        p_value=p_value,\n",
    "        significance=significance,\n",
    "        critical_value=critical_value,\n",
    "        test_name=\"two sample z-test\",\n",
    "        null_name=f\"mu_x = mu_y\",\n",
    "        alternative_name=f\"mu_x {'!=' if tail == 'both' else ('>' if tail == 'right' else '<')} mu_y\"\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:14.342912Z",
     "iopub.status.busy": "2024-11-03T12:40:14.342537Z",
     "iopub.status.idle": "2024-11-03T12:40:16.423614Z",
     "shell.execute_reply": "2024-11-03T12:40:16.422563Z",
     "shell.execute_reply.started": "2024-11-03T12:40:14.342875Z"
    }
   },
   "outputs": [],
   "source": [
    "data_x = games_df[(games_df['site'] == 'Moscow') & (games_df['date'] >= 2010) \\\n",
    "                & (games_df['date'] <= 2019) & (games_df['control'] == 'slow')]['elo_average']\n",
    "\n",
    "data_y = games_df[(games_df['site'] == 'Moscow') & (games_df['date'] >= 2000) \\\n",
    "                & (games_df['date'] <= 2009) & (games_df['control'] == 'slow')]['elo_average']\n",
    "\n",
    "z_test_two_sample(data_x, data_y, tail='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение**: Мы отвергли нулевую гипотезу - а значит в 2010-2019 годах рейтинг не был лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1. Инфляция рейтинга (5 баллов)\n",
    "\n",
    "В течение времени правила подсчета рейтинга менялись. Для сравнения возьмем партии в классическом временном контроле и их рейтинги за периоды 2000-2009 года и 2010-2019 год. Нарисуйте гистограммы, которые описывают распределение усредненных рейтингов оппонентов в партиях за эти периоды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:16.425589Z",
     "iopub.status.busy": "2024-11-03T12:40:16.425072Z",
     "iopub.status.idle": "2024-11-03T12:40:19.113638Z",
     "shell.execute_reply": "2024-11-03T12:40:19.112343Z",
     "shell.execute_reply.started": "2024-11-03T12:40:16.425546Z"
    }
   },
   "outputs": [],
   "source": [
    "games_df_1 = games_df[(games_df['control'] == 'slow') & (games_df['date'] >= 2000) & (games_df['date'] <= 2019)].copy()\n",
    "games_df_1['decade'] = np.where(games_df_1['date'] >= 2010, '2010-2019', '2000-2009')\n",
    "\n",
    "px.histogram(\n",
    "    games_df_1, \n",
    "    x='elo_average',\n",
    "    barmode='overlay',\n",
    "    color='decade',\n",
    "    title=\"Distribution of game\\'s averaged elo in slow format between in 2000-2009 and 2010-2019\",\n",
    "    width=900,\n",
    "    nbins=600,\n",
    ").show(renderer='png')\n",
    "\n",
    "px.histogram(\n",
    "    games_df_1, \n",
    "    x='elo_average',\n",
    "    color='decade',\n",
    "    facet_row='decade', \n",
    "    title=\"Distribution of game\\'s averaged elo in slow format between in 2000-2009 and 2010-2019\",\n",
    "    width=900,\n",
    "    height=800,\n",
    "    nbins=600,\n",
    ").show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распространено мнение, что в силу изменений правил подсчета, высокий рейтинг стало получить легче --- произошла инфляция рейтинга. Проверьте, так ли это на самом деле, с помощью рангового критерия [Уилкоксона-Манна-Уитни](http://www.machinelearning.ru/wiki/index.php?title=Критерий_Уилкоксона-Манна-Уитни). В качестве распределения статистики можете брать подходящую аппроксимацию нормальным распределением с поправкой на повторяющиеся значения. Как и ранее,\n",
    "1. сформулируйте нулевую гипотезу и альтернативу; объясните смысл математической формулировки нулевой гипотезы;\n",
    "2. укажите статистику и её распределение при верной нулевой гипотезе;\n",
    "3. реализуйте тест и проверьте гипотезу на уровне значимости 0.05;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X - \\text{выборка 2010-2019 годов}, Y - \\text{выборка 2000-2009 годов}$\n",
    "\n",
    "$$\n",
    "    H_0 : P[X > Y] = 1/2 \\\\\n",
    "    H_1 : P[X < Y] > 1/2\n",
    "$$\n",
    "\n",
    "Смысл - проверяем что распределения одинаковаые, против альтернативы, что распределение $X$ смещено влево отностительно $Y$.\n",
    "\n",
    "$R$ - ранги совместно упорядоченных наблюдений\n",
    "\n",
    "$$\n",
    "U_X =  n_1 n_2 + \\frac{n_1 (n_1 + 1)}{2} - R_X \\\\ \n",
    "U_Y =   n_1 n_2 + \\frac{n_2 (n_2 + 1)}{2} - R_Y \\\\\n",
    "$$\n",
    "\n",
    "Дальше в зависимости атальтернативы выбираем знаение $U$:\n",
    "- $P(X > Y) > 1/2 \\implies U = U_X$\n",
    "- $P(Y > X) > 1/2 \\implies U = U_Y$\n",
    "- $P(X > Y) != 1/2 \\implies U = \\text{min}(U_X, U_Y)$\n",
    "\n",
    "Запишем\n",
    "\n",
    "$$z = \\frac{U - \\mu_U}{\\sigma_U} ; \\qquad z \\sim_{n \\to \\infty} \\mathcal{N}(0, 1)$$\n",
    "\n",
    "\n",
    "Где\n",
    "\n",
    "$$\n",
    "\\mu_U = \\frac{n_1 n_2}{2}\n",
    "$$\n",
    "\n",
    "И в случае не абсолютно непрерывных распределений\n",
    "\n",
    "$$\n",
    "\\sigma_U = \\sqrt{\\frac{n_1 n_2 (n_1 + n_2 + 1)}{12} - \\frac{n_1 n_2 \\sum_k (t_k^3 - t_k)}{12 \\cdot (n_1 + n_2) \\cdot (n_1 + n_2 - 1)}}; \\qquad t_k - \\text{количество дублей ранга } k \\\\\n",
    "$$\n",
    "\n",
    "Для правосторонего и левостороннего отвергаем если  $z < z_{\\alpha}$, а для двухстороннего если  $z < z_{\\alpha / 2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:19.115795Z",
     "iopub.status.busy": "2024-11-03T12:40:19.115315Z",
     "iopub.status.idle": "2024-11-03T12:40:19.134000Z",
     "shell.execute_reply": "2024-11-03T12:40:19.132720Z",
     "shell.execute_reply.started": "2024-11-03T12:40:19.115742Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata # this can help. See docs.\n",
    "\n",
    "def mwu_test(sample_x : ArrayLike, sample_y : ArrayLike, significance : float = 0.05, tail : hypothesis_side = 'both') -> StatTestResult:\n",
    "    \"\"\"        \n",
    "        Performs Mann–Whitney U-test with correct support for ties in the data. \n",
    "        REMARK: Test uses normal approximation for the distribution of test statistics\n",
    "                under null hypothesis.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        sample_x : ArrayLike\n",
    "            first sample for the U-test \n",
    "        sample_y : ArrayLike\n",
    "            second sample for the U-test\n",
    "        significance : float\n",
    "            significance level for the performed test\n",
    "        tail : Literal[\"both\", \"left\", \"right\"]\n",
    "            alternative side\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        res : StatTestResult\n",
    "            An object containing infomration about test results\n",
    "    \"\"\"\n",
    "    \n",
    "    combined_data = np.concatenate([sample_x, sample_y])\n",
    "    ranks = rankdata(combined_data)\n",
    "    \n",
    "    n_x = len(sample_x)\n",
    "    n_y = len(sample_y)\n",
    "    \n",
    "    ranks_x = ranks[:n_x]\n",
    "    ranks_y = ranks[n_x:]\n",
    "    \n",
    "    nn = n_x * n_y\n",
    "    n = n_x + n_y\n",
    "    \n",
    "    U_x = (nn + n_x * (n_x + 1) / 2 - np.sum(ranks_x))\n",
    "    U_y = (nn + n_y * (n_y + 1) / 2 - np.sum(ranks_y))\n",
    "            \n",
    "    _, counts = np.unique(ranks, return_counts=True)\n",
    "           \n",
    "    sigma_ties = np.sqrt(nn / 12 * (n + 1 - np.sum(counts**3 - counts) / (n * (n - 1))))\n",
    "    \n",
    "    if tail == 'both':\n",
    "                \n",
    "        U = min(U_x, U_y)\n",
    "        z = (U - nn / 2) /  sigma_ties\n",
    "        p_value = 2 * sps.norm.cdf(z)\n",
    "                \n",
    "    elif tail == 'right':\n",
    "        \n",
    "        U = U_x\n",
    "        z = (U - nn / 2) /  sigma_ties\n",
    "        p_value = sps.norm.cdf(z)\n",
    "                \n",
    "    elif tail == 'left':\n",
    "        \n",
    "        U = U_y\n",
    "        z = (U - nn / 2) /  sigma_ties\n",
    "        p_value = sps.norm.cdf(z)\n",
    "        \n",
    "    critical_value = sps.norm.ppf(1 - significance / 2) if tail == 'both' \\\n",
    "        else (sps.norm.ppf(1 - significance) if tail == 'right' else sps.norm.ppf(significance))\n",
    "    \n",
    "    result = StatTestResult(\n",
    "        statistics=U,\n",
    "        p_value=p_value,\n",
    "        significance=significance,\n",
    "        critical_value=critical_value,\n",
    "        test_name=\"U-test\",\n",
    "        null_name=f\"P[x < y] = 1/2\",\n",
    "        alternative_name=f\"P[x {'>' if tail == 'right' else '<'} y] {'!=' if tail == 'both' else '>'} 1/2\"\n",
    "    )\n",
    "    \n",
    "    print('Я возвращаю U статистику, которая используется для проверки гипотезу, а не как в scipy.\\n')\n",
    "\n",
    "    print(f\"z = {z},    U_x = {U_x}    U_y = {U_y}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:19.136143Z",
     "iopub.status.busy": "2024-11-03T12:40:19.135659Z",
     "iopub.status.idle": "2024-11-03T12:40:20.403668Z",
     "shell.execute_reply": "2024-11-03T12:40:20.402464Z",
     "shell.execute_reply.started": "2024-11-03T12:40:19.136070Z"
    }
   },
   "outputs": [],
   "source": [
    "data_x = games_df[(games_df['date'] >= 2010) \\\n",
    "                & (games_df['date'] <= 2019) & (games_df['control'] == 'slow')]['elo_average']\n",
    "\n",
    "data_y = games_df[(games_df['date'] >= 2000) \\\n",
    "                & (games_df['date'] <= 2009) & (games_df['control'] == 'slow')]['elo_average']\n",
    "\n",
    "mwu_test(data_x, data_y, tail='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.mannwhitneyu(data_x, data_y, alternative='less')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение**: Мы отвергли нулевую гипотезу - а значит в 2010-2019 годах рейтинг не был лучше и инфляции не произошло."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2. Рейтинги и исход партий (7.5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исследуйте как, в зависимости от рейтинга участников, меняется распределение исхода партии. Мы предлагаем вам изучить как\n",
    "- Разница в рейтинге влияет на шансы на результативный исход (победа одной из сторон)\n",
    "- С ростом среднего рейтинга участников меняются шансы на победу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разрыв рейтинга и шансы на победу (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуйте гистограммы, показывающее как устроены исходы партий в зависимости от разницы в рейтинге для партий в разных формах временного контролля. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    games_df, \n",
    "    x='elo_difference',\n",
    "    color='result',\n",
    "    facet_row='control', \n",
    "    barmode='overlay',\n",
    "    title=\"Distribution of game\\'s elo difference relatively to result in different formats\",\n",
    "    width=900,\n",
    "    height=900,\n",
    "    nbins=800,\n",
    "    range_x=[-1200, 1200]\n",
    ").update_yaxes(matches=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте гипотезу \"симметрии\":\n",
    "> Правда ли что шансы победы белых при разрыве рейтинга между участниками в $X$ пунктов такие же, как шансы на победу чёрных при разрыве рейтинга в $-X$ пунктов?\n",
    "\n",
    "Для проверки такой гипотезы будем использовать критерий $\\chi^2$ для проверки независимости факторов. \n",
    "- Подумайте, как должна выглядеть факторная таблица в этом случае?\n",
    "- Сформулируйте как интерпретировать нулевую гипотезу критерия $\\chi^2$ в контексте проверяемой нами гипотезы.\n",
    "- Реализуйте проверку гипотезы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критерий однородности хи-хи для проверки независимости вероятностей победы от цвета. В таблице два столбца - результаты партий без нечьих, и две строки - знак разрыва рейтинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df[\"elo_difference_sign\"] = np.where(games_df[\"elo_difference\"] > 0, \"X > 0\", \"X < 0\")\n",
    "observed = pd.crosstab(games_df[\"elo_difference_sign\"], games_df[\"result\"]).drop(columns=['1/2-1/2'])\n",
    "observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем контексте справедливость нулевой гипотезы будет значить, что шансы победы белых при разрыве рейтинга между участниками в $X$ пунктов такие же, как шансы на победу чёрных при разрыве рейтинга в $-X$ пунктов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:36.111778Z",
     "iopub.status.busy": "2024-11-03T12:40:36.111310Z",
     "iopub.status.idle": "2024-11-03T12:40:36.122487Z",
     "shell.execute_reply": "2024-11-03T12:40:36.121152Z",
     "shell.execute_reply.started": "2024-11-03T12:40:36.111726Z"
    }
   },
   "outputs": [],
   "source": [
    "def chi2_contingency(observed : ArrayLike, significance : float = 0.05) -> StatTestResult:\n",
    "    \"\"\"\n",
    "        Performs chi-square independence test test for contingency table\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        observed : ArrayLike\n",
    "            contingency tablefor the test \n",
    "        significance : float\n",
    "            significance level for the performed test\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        res : StatTestResult\n",
    "            An object containing infomration about test results\n",
    "    \"\"\"\n",
    "    \n",
    "    n = np.sum(observed)\n",
    "    \n",
    "    n_, m_ = observed.shape\n",
    "\n",
    "    p_j = 1 / n * np.sum(observed, axis=1)\n",
    "    q_k = 1 / n * np.sum(observed, axis=0)\n",
    "\n",
    "    T = 0\n",
    "    for j in range(n_):\n",
    "        for k in range(m_):\n",
    "\n",
    "            np_jq_k = n * p_j[j] * q_k[k]\n",
    "\n",
    "            T += (observed[j][k] - np_jq_k)**2 / np_jq_k\n",
    "\n",
    "    critical_value = sps.chi2.ppf(1 - significance, (n_ - 1) * (m_ - 1))\n",
    "    \n",
    "    p_value = sps.chi2.sf(T, (n_ - 1) * (m_ - 1))\n",
    "    \n",
    "    result = StatTestResult(\n",
    "        statistics=T,\n",
    "        p_value=p_value,\n",
    "        significance=significance,\n",
    "        critical_value=critical_value,\n",
    "        test_name=\"Chi2-test\",\n",
    "        null_name=f\"p_1 = p_2 = ... = p_k\",\n",
    "        alternative_name=\"not H0\"\n",
    "    )\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте сформулированную выше гипотезу для ваших данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:39.116184Z",
     "iopub.status.busy": "2024-11-03T12:40:39.115790Z",
     "iopub.status.idle": "2024-11-03T12:40:39.170345Z",
     "shell.execute_reply": "2024-11-03T12:40:39.169169Z",
     "shell.execute_reply.started": "2024-11-03T12:40:39.116138Z"
    }
   },
   "outputs": [],
   "source": [
    "chi2_contingency(observed.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение**: Ну очев, любой шахматист знает что у белых преимущество, даже по графикам видно что зеленая гистограмма выше, чем красная."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Средний рейтинг и распределение исходов (2.5 балла)\n",
    "Существует распространеное мнение, что чем выше рейтинг участников партии, тем более вероятно, что итогом партии станет ничья. Постройте гистограммы показывающее как устроены исходы партий в зависимости от рейтинга партии (``elo_average``) для партий в разных формах временного контролля. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:39.172550Z",
     "iopub.status.busy": "2024-11-03T12:40:39.172084Z",
     "iopub.status.idle": "2024-11-03T12:40:54.986912Z",
     "shell.execute_reply": "2024-11-03T12:40:54.985575Z",
     "shell.execute_reply.started": "2024-11-03T12:40:39.172478Z"
    }
   },
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    games_df, \n",
    "    x='elo_average',\n",
    "    color='result',\n",
    "    facet_row='control', \n",
    "    barmode='overlay',\n",
    "    title=\"Distribution of game\\'s averaged elo relatively to result in different formats\",\n",
    "    width=900,\n",
    "    height=900,\n",
    "    nbins=300\n",
    ").update_yaxes(matches=None).show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласно ChessBase, игроков можно условно делить на следующие категории, в зависимости от их рейтинга:\n",
    "- 0-1000 Begginer\n",
    "- 1000-1600 Average club player level\n",
    "- 1600-2100 Strong club player level\n",
    "- 2100-2300 International league player\n",
    "- 2300-2450 International Master (IM) level\n",
    "- 2450-2650 Grandmaster (GM) level\n",
    "- \\> 2650 Supergrandmaster, world champion level\n",
    "\n",
    "Вместо игроков, мы будем брать усредненный рейтинг оппонентов в партии и применять классификацию выше. С помощью статистических методов, проверьте влияет ли класс партии на распределение исходов. Используйте уже знакомый вам тест $\\chi^2$.\n",
    "- Подумайте, как должна выглядеть факторная таблица в этом случае?\n",
    "- Сформулируйте как интерпретировать нулевую гипотезу критерия $\\chi^2$ в контексте проверяемой нами гипотезы.\n",
    "- Реализуйте проверку гипотезы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T11:20:52.431379Z",
     "iopub.status.busy": "2024-11-03T11:20:52.430905Z",
     "iopub.status.idle": "2024-11-03T11:20:52.439254Z",
     "shell.execute_reply": "2024-11-03T11:20:52.437572Z",
     "shell.execute_reply.started": "2024-11-03T11:20:52.431324Z"
    }
   },
   "source": [
    "Таблица выгдядит так"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:54.989069Z",
     "iopub.status.busy": "2024-11-03T12:40:54.988616Z",
     "iopub.status.idle": "2024-11-03T12:40:56.523247Z",
     "shell.execute_reply": "2024-11-03T12:40:56.521912Z",
     "shell.execute_reply.started": "2024-11-03T12:40:54.989011Z"
    }
   },
   "outputs": [],
   "source": [
    "bins   = [0, 1000, 1600, 2100, 2300, 2450, 2650, 3000]\n",
    "labels = ['Begginer', 'Average', 'Strong', 'International', 'IM', 'GM', 'SuperGM']\n",
    "\n",
    "def get(df): \n",
    "    df = df.copy()\n",
    "    df['category'] = pd.cut(df[\"elo_average\"], bins=bins, labels=labels)\n",
    "    observed = pd.crosstab(df[\"category\"], df[\"result\"])\n",
    "    return observed\n",
    "\n",
    "get(games_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем контексте справедливость нулевой гипотезы будет значить, что уровень скилла игроков не влияет на распределение исходов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_blitz = get(games_df[games_df['control'] == 'blitz'])\n",
    "table_blitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы не можем иметь слишком маленькие бакеты для этого статтеста, так что дропнем Begginer для простоты\n",
    "# можно было бы объединить его с Average, но мне лень \n",
    "\n",
    "print('Testing ... for slow format')\n",
    "chi2_contingency(table_blitz.drop('Begginer').to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rapid = get(games_df[games_df['control'] == 'rapid'])\n",
    "table_rapid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мы не можем иметь слишком маленькие бакеты для этого статтеста, так что дропнем Begginer для простоты\n",
    "\n",
    "print('Testing ... for rapid format')\n",
    "chi2_contingency(table_rapid.drop('Begginer').to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:56.524889Z",
     "iopub.status.busy": "2024-11-03T12:40:56.524561Z",
     "iopub.status.idle": "2024-11-03T12:40:56.537702Z",
     "shell.execute_reply": "2024-11-03T12:40:56.536347Z",
     "shell.execute_reply.started": "2024-11-03T12:40:56.524854Z"
    }
   },
   "outputs": [],
   "source": [
    "table_slow = get(games_df[games_df['control'] == 'slow'])\n",
    "table_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:56.556807Z",
     "iopub.status.busy": "2024-11-03T12:40:56.556385Z",
     "iopub.status.idle": "2024-11-03T12:40:56.574464Z",
     "shell.execute_reply": "2024-11-03T12:40:56.573234Z",
     "shell.execute_reply.started": "2024-11-03T12:40:56.556763Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Testing ... for slow format')\n",
    "chi2_contingency(table_slow.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение**: Мы видим, что распределение вероятностей исходов партий зависят от уровня скилла игроков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема в том что критерий $\\chi^2$ позволяет нам проверять факторы на зависимость/независимость, но ничего не говорит о структуре этой зависимости. Реализуйте вычисление ранговой корреляции Спирмена и посчитайте её, чтобы оценить есть ли \n",
    "- Монотонная зависимость между *шансами на ничью* и *рангом партии*\n",
    "- Монотонная зависимость между *разницей шансов на победу у белых и у чёрных* и *рангом партии*\n",
    "\n",
    "Используйте для этого партии сыгранные в блиц-контроле и дайте интерпретацию полученным результатам. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:56.576341Z",
     "iopub.status.busy": "2024-11-03T12:40:56.575941Z",
     "iopub.status.idle": "2024-11-03T12:40:56.600135Z",
     "shell.execute_reply": "2024-11-03T12:40:56.598846Z",
     "shell.execute_reply.started": "2024-11-03T12:40:56.576301Z"
    }
   },
   "outputs": [],
   "source": [
    "table_blitz['draw_prob'] = table_blitz['1/2-1/2'] / table_blitz.sum(axis=1)\n",
    "table_blitz['white_win_prob'] = table_blitz['1-0'] / table_blitz.sum(axis=1)\n",
    "table_blitz['black_win_prob'] =  table_blitz['0-1'] / table_blitz.sum(axis=1)\n",
    "table_blitz['dominance'] = table_blitz['white_win_prob'] - table_blitz['black_win_prob']\n",
    "\n",
    "table_blitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:56.601862Z",
     "iopub.status.busy": "2024-11-03T12:40:56.601466Z",
     "iopub.status.idle": "2024-11-03T12:40:56.615338Z",
     "shell.execute_reply": "2024-11-03T12:40:56.614059Z",
     "shell.execute_reply.started": "2024-11-03T12:40:56.601822Z"
    }
   },
   "outputs": [],
   "source": [
    "def spearman_rank_correlation(observations : ArrayLike) -> float:\n",
    "    \"\"\"        \n",
    "        Calculates spearmean's rank correlation coefficient for data in the format\n",
    "            (1, X[1]), (2, X[2]), .... (n, X[n])\n",
    "        i.e. for the paired rank data sorted by the first component. No ties assumed\n",
    "        in the data X.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        observed : ArrayLike\n",
    "             array of values X[1], X[2], ... X[n], \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        spearman : float \n",
    "            value of the spearman correlation for the given data\n",
    "    \"\"\"\n",
    "    n = len(observations)\n",
    "    \n",
    "    ranks_x = np.arange(1, n + 1)\n",
    "    ranks_y = rankdata(observations)\n",
    "    \n",
    "    centred_x = ranks_x - np.mean(ranks_x)\n",
    "    centred_y = ranks_y - np.mean(ranks_y)\n",
    "\n",
    "    rho = np.sum(centred_x * centred_y) / np.sqrt(np.sum(centred_x**2) * np.sum(centred_y**2))\n",
    "\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:56.623307Z",
     "iopub.status.busy": "2024-11-03T12:40:56.622684Z",
     "iopub.status.idle": "2024-11-03T12:40:56.630583Z",
     "shell.execute_reply": "2024-11-03T12:40:56.629433Z",
     "shell.execute_reply.started": "2024-11-03T12:40:56.623264Z"
    }
   },
   "outputs": [],
   "source": [
    "rho = spearman_rank_correlation(table_blitz['draw_prob'].to_numpy())\n",
    "print(f'Correlation between draw odds and game rank: {rho}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:40:56.632736Z",
     "iopub.status.busy": "2024-11-03T12:40:56.632313Z",
     "iopub.status.idle": "2024-11-03T12:40:56.643795Z",
     "shell.execute_reply": "2024-11-03T12:40:56.642665Z",
     "shell.execute_reply.started": "2024-11-03T12:40:56.632695Z"
    }
   },
   "outputs": [],
   "source": [
    "rho = spearman_rank_correlation(table_blitz['dominance'].to_numpy())\n",
    "print(f'Correlation between white dominance over black and game rank: {rho}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение.** Существует строгая монотонная зависимость между уровнем игры и вероятностью ничьи. Между уровнем игры и вероятностью побуды белых существует монотонная зависимость, но она столь выражена как для ничьих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3. Статистика дебютов (2.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другим распространённым мнением является то что выбор дебюта на высоком уровне не влияет на результативность партии. Все дебюты, согласно энциклопедии шахматных дебютов (ECO) делятся на 5 категорий\n",
    "- A: Фланговые варианты.\n",
    "- B: Полуоткрыте варианты.\n",
    "- C: Открытые варианты.\n",
    "- D: Закрытые и полузакрытые варианты.\n",
    "- E: Системы типа индийской защиты.\n",
    "\n",
    "Так как у нас нет доступа к партиям ИИ, которые сейчас считаются эталоном точной игры, мы ограничимся данными по партиям уровня супергроссмейстеров. \n",
    "Используя статистические методы, проверьте:\n",
    "- Есть ли разница в предпочтениях дебютов (с точки зрения приведенных выше категорий) между партиями уровня супергроссмейстеров и партиями уровня гроссмейстеров в классическом временном контроле? \n",
    "- Правда ли что выбор между открытым (C) и закрытым (D) началом не влияет на распределение исхода партии? Проверьте это для разных форм временного контроля. Используйте партии только уровня супергроссмейстеров.\n",
    "\n",
    "Для проверки будем использовать критерий $\\chi^2$ (снова). Для каждой гипотезы, которое вы собираетесь проверять:\n",
    "- сделайте визуализацию соответствующих данных;\n",
    "- сформулируйте нулевую и альтернативную гипотезу. Опишите как применить критерий $\\chi^2$ для проверки этих гипотез;\n",
    "- реализуйте проверку гипотезы и дайте интерпретацию результатам;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну снова гипотеза что строки таблицы ниже однородны. Делаем табличку и закидываем в статтест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:41:01.911605Z",
     "iopub.status.busy": "2024-11-03T12:41:01.911251Z",
     "iopub.status.idle": "2024-11-03T12:41:01.922480Z",
     "shell.execute_reply": "2024-11-03T12:41:01.921248Z",
     "shell.execute_reply.started": "2024-11-03T12:41:01.911566Z"
    }
   },
   "outputs": [],
   "source": [
    "bins   = [0, 1000, 1600, 2100, 2300, 2450, 2650, 3000]\n",
    "labels = ['Begginer', 'Average', 'Strong', 'International', 'IM', 'GM', 'SuperGM']\n",
    "\n",
    "games_df['category'] = pd.cut(games_df[\"elo_average\"], bins=bins, labels=labels)\n",
    "\n",
    "px.histogram(\n",
    "    games_df[(games_df['control'] == 'slow') & (games_df['category'].isin(['GM', 'SuperGM']))],\n",
    "    x='opening', facet_row='category', \n",
    "    color='opening',\n",
    "    title=\"Preferences of game\\'s openings with GMs and SuperGMs\"\n",
    ").update_yaxes(matches=None).show(renderer='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fter = (games_df['control'] == \"slow\")\n",
    "observed = pd.crosstab(games_df[fter][\"category\"], games_df[fter][\"opening\"]).loc[['GM', 'SuperGM']]\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_contingency(observed.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение**: есть разница в предпочтениях дебютов между партиями уровня супергроссмейстеров и партиями уровня гроссмейстеров в классическом временном контроле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверьте влияет ли выбор между открытым и закрытым началом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И опять гипотеза что строки таблицы ниже однородны. Делаем табличку и закидываем в статтест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(\n",
    "    games_df[(games_df['category'] == 'SuperGM') & (games_df['opening'].isin(['C', 'D']))], \n",
    "    x='opening',\n",
    "    color='result', barmode='group',\n",
    "    facet_col='control', \n",
    "    title=\"Game\\'s openings with SuperGMs and game's results\",\n",
    ").update_yaxes(matches=None).show(renderer='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fter = (games_df['control'] == \"slow\")\n",
    "observed = pd.crosstab(games_df[fter][\"opening\"], games_df[fter][\"result\"]).loc[['C', 'D']]\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:41:01.924443Z",
     "iopub.status.busy": "2024-11-03T12:41:01.924005Z",
     "iopub.status.idle": "2024-11-03T12:41:02.020796Z",
     "shell.execute_reply": "2024-11-03T12:41:02.019720Z",
     "shell.execute_reply.started": "2024-11-03T12:41:01.924401Z"
    }
   },
   "outputs": [],
   "source": [
    "chi2_contingency(observed.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fter = (games_df['control'] == \"rapid\")\n",
    "observed = pd.crosstab(games_df[fter][\"opening\"], games_df[fter][\"result\"]).loc[['C', 'D']]\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_contingency(observed.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fter = (games_df['control'] == \"blitz\")\n",
    "observed = pd.crosstab(games_df[fter][\"opening\"], games_df[fter][\"result\"]).loc[['C', 'D']]\n",
    "observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_contingency(observed.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что изменится если брать уровень значимости 0.01? А если брать уровень значимости 0.1? Дайте ответы на эти вопросы и напишите интерпретацию полученных результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fter = (games_df['control'] == \"blitz\")\n",
    "observed = pd.crosstab(games_df[fter][\"opening\"], games_df[fter][\"result\"]).loc[['C', 'D']]\n",
    "chi2_contingency(observed.to_numpy(), significance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fter = (games_df['control'] == \"rapid\")\n",
    "observed = pd.crosstab(games_df[fter][\"opening\"], games_df[fter][\"result\"]).loc[['C', 'D']]\n",
    "chi2_contingency(observed.to_numpy(), significance=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fter = (games_df['control'] == \"slow\")\n",
    "observed = pd.crosstab(games_df[fter][\"opening\"], games_df[fter][\"result\"]).loc[['C', 'D']]\n",
    "chi2_contingency(observed.to_numpy(), significance=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Заключение**: выбор между открытым (C) и закрытым (D) началом зтатзначимо (p-value > 0.05) влияет на распределение исхода партии только для классическийх шахмат и рапида. Для блитца выбор дебюта играет меньшую роль так как там сильно сложнее реализовать стратегическое преимущество. \n",
    "\n",
    "Изменение уровня значимости не повлияло на результаты - у нас много данных и тест вышел достаточно мощный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 4. Исследование длин партий в разных формах временного контроля (10 баллов)\n",
    "\n",
    "Попробуйте разобраться в том, какому распределению следуют длительности партий в формате рапид. Выберете несколько распределений и попробуйте оценить их параметры. Постройте гистограммы на которых изображено распределение длительности партий и теоретические плотности распределений с оценёнными параметрами. \n",
    "\n",
    "Для оценки параметров распределений можно использовать метод ``fit()`` класса ``scipy.rv_continious()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = games_df[games_df['control'] == 'rapid']['length']\n",
    "fig = px.histogram(data, x='length', opacity=0.2, nbins=300, histnorm='probability density')\n",
    "\n",
    "fig.update_layout(title=\"Imperical pdf\")\n",
    "fig.show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Типикл гамма распределение (лол, я был не прав), но го чекнем еще и другие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma, lognorm, exponnorm, invgauss, invgamma, rayleigh, maxwell\n",
    "\n",
    "distributions = {\n",
    "    \"Gamma\": gamma,\n",
    "    \"LogNormal\": lognorm,\n",
    "    \"ExponNorm\": exponnorm,\n",
    "    \"InvGauss\": invgauss,\n",
    "    \"InvGamma\": invgamma,\n",
    "    \"Rayleigh\": rayleigh,\n",
    "    \"Maxwell\": maxwell\n",
    "}\n",
    "\n",
    "x_values = np.linspace(data.min(), data.max(), len(data))\n",
    "\n",
    "for name, dist in distributions.items():\n",
    "    \n",
    "    params = dist.fit(data)\n",
    "    pdf = dist.pdf(x_values, *params)\n",
    "    fig.add_trace(go.Scatter(x=x_values, y=pdf, mode='lines', name=name))\n",
    "\n",
    "fig.update_layout(title=\"Imperical pdf and fitted distrubutions\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогу отобрал ExponNormal, LonNormal, и InvGamma (которое совпадает с LonNormal на зафиченных параметрах)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x='length', opacity=0.2, nbins=300, histnorm='probability density')\n",
    "\n",
    "distributions = {\n",
    "#     \"Gamma\": gamma,\n",
    "    \"LogNormal\": lognorm,\n",
    "    \"ExponNorm\": exponnorm,\n",
    "#     \"InvGauss\": invgauss,\n",
    "    \"InvGamma\": invgamma,\n",
    "#     \"Rayleigh\": rayleigh,\n",
    "#     \"Maxwell\": maxwell\n",
    "}\n",
    "\n",
    "for name, dist in distributions.items():\n",
    "    \n",
    "    params = dist.fit(data)\n",
    "    pdf = dist.pdf(x_values, *params)\n",
    "    fig.add_trace(go.Scatter(x=x_values, y=pdf, mode='lines', name=name))\n",
    "\n",
    "\n",
    "fig.update_layout(title=\"Imperical pdf and fitted distrubutions\")\n",
    "fig.show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите три наиболее на ваш взгляд подходящих распределения и постройте для них Q-Q график. Подробнее про Q-Q графики можно прочитать [здесь](https://habr.com/ru/articles/578754/) (обратите внимание, что в статье делается упор на Q-Q графики относительно нормального распределения --- вам же нужно построить графики относительно распределений, параметры которых вы оценили)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:41:05.443697Z",
     "iopub.status.busy": "2024-11-03T12:41:05.443322Z",
     "iopub.status.idle": "2024-11-03T12:41:05.452834Z",
     "shell.execute_reply": "2024-11-03T12:41:05.451566Z",
     "shell.execute_reply.started": "2024-11-03T12:41:05.443658Z"
    }
   },
   "outputs": [],
   "source": [
    "def qqplot(data : ArrayLike, distribution: stats.rv_continuous,  quantiles : int,  ax : plt.axis) -> plt.axis:\n",
    "    \"\"\"\n",
    "        Plots Q-Q plot agains theoretical distribution. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : ArrayLike\n",
    "            sample data\n",
    "        distribution: stats.rv_continuous\n",
    "            theoretical distribution agains which quantiles will be plotted\n",
    "        quantiles: int\n",
    "            number of quantiles (must be less than size of the data)\n",
    "        ax: plt.axis\n",
    "            PyPlot Axis object, on which QQ-plot should be plotted\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ax: plt.axis \n",
    "            PyPlot Axis object with QQ-plot\n",
    "    \"\"\"\n",
    "    \n",
    "    params = dist.fit(data)\n",
    "    \n",
    "    theoretical_quantiles = np.linspace(0, 1, quantiles + 2)[1:-1]\n",
    "    theoretical_values = distribution.ppf(theoretical_quantiles, *params)\n",
    "\n",
    "    sample_quantiles = np.percentile(data, theoretical_quantiles * 100)\n",
    "\n",
    "    ax.scatter(theoretical_values, sample_quantiles, label=\"quantiles\")\n",
    "    ax.plot(theoretical_values, theoretical_values, color='red', linestyle='--', label='best fit')\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:41:05.455298Z",
     "iopub.status.busy": "2024-11-03T12:41:05.454459Z",
     "iopub.status.idle": "2024-11-03T12:41:06.203555Z",
     "shell.execute_reply": "2024-11-03T12:41:06.202148Z",
     "shell.execute_reply.started": "2024-11-03T12:41:05.455247Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "distributions = {\n",
    "#     \"Gamma\": gamma,\n",
    "    \"LogNormal\": lognorm,\n",
    "    \"ExponNorm\": exponnorm,\n",
    "#     \"InvGauss\": invgauss,\n",
    "    \"InvGamma\": invgamma,\n",
    "#     \"Rayleigh\": rayleigh,\n",
    "#     \"Maxwell\": maxwell\n",
    "}\n",
    "\n",
    "for i, (name, dist) in enumerate(distributions.items()):\n",
    "    qqplot(data, distribution=dist, quantiles=100, ax=axs[i])\n",
    "    axs[i].set_title(name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ммм, три одинаковых графика, очень полезно. По грфику с pdf мне кажется что это эксп-нормальное."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " На основе всего выше сделанного выберете одно распределение, которое вам кажется наиболее подходящим. После того как вы выбрали распределение $F_0$, проверьте соответствующую гипотезу согласия. Конкретнее, проверьте гипотезу\n",
    "$$\n",
    "H_0: X_1,..,X_n \\sim F_0\n",
    "$$\n",
    "против альтернативы\n",
    "$$\n",
    "H_A: X_1,..,X_n \\nsim F_0\n",
    "$$\n",
    "\n",
    "\n",
    "Такую гипотезу часто проверяют с помощью статистики критерия Колмогорова-Смирнова:\n",
    "$$\n",
    "D = \\sqrt{n} \\sup_x \\vert F_{0} - \\hat{F}(x)\\vert,\n",
    "$$\n",
    "где $\\hat{F}$ -- эмпирическая функция распределения, которая задётся как\n",
    "$$\n",
    "\\hat{F}(x) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}(X_i \\leq x).\n",
    "$$\n",
    "Выражение $1(условие)$ равно $1$, если условие верно и $0$ в противном случае -- так выше считается количество элементов выборки $\\leq x$. Статистика $D$ при больших $n$ (сотен уже достаточно) имеет распределение Колмогорова, так что можно построить критерий для проверки. Чтобы упростить техническую часть с подсчётом $D$, воспользуйтесь готовым тестом из пакета scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:41:06.205699Z",
     "iopub.status.busy": "2024-11-03T12:41:06.205304Z",
     "iopub.status.idle": "2024-11-03T12:41:06.361753Z",
     "shell.execute_reply": "2024-11-03T12:41:06.360385Z",
     "shell.execute_reply.started": "2024-11-03T12:41:06.205659Z"
    }
   },
   "outputs": [],
   "source": [
    "stats.kstest(data, 'exponnorm', exponnorm.fit(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объясните, почему получилось такое значение несмотря на то, что подобранное вами распределение достаточно неплохо описывает данные? Подумайте, можно ли как-то изменить процедуру проверки для того чтобы можно было воспользоваться этим тестом? Обратите внимание на две вещи:\n",
    "1. Как считается статистка критерия КС и почему для наших данных эмпирическая функция распределения никогда не будет сходится к функции распределения выбранного вами распределения? Как можно сделать дискретные данные  не-дискретными?\n",
    "2.  Обратите внимание на выброс в данных в районе где достигается значение статистики критерия (statistic location). С чем может быть связан этот выброс и как можно было бы его устранить?\n",
    "\n",
    "Опишите и реализуйте измененную процедуру. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот критерий очень строгий, а у нас дискретное распределение, значит $\\vert F_{0} - \\hat{F}(x)\\vert$ не сходится к нуля с ростом $n$ даже для вроде как одинаковых распределений. К тому же у нас есть выброс в районе где достигается значение статистики критерия (statistic location), что сильно ужудшает результаты теста. \n",
    "\n",
    "Для решения проблемы с дискретностью респределения добавим к нему случайный гаусовский шум с нулевым средним.\n",
    "\n",
    "Методологически сложно выкинуть 'плотные' точки из распределения так, чтобы не оверфитнуться, но другие способы не работаю так что будем делать так - а именно разобъем данные из интересующей нас области на бакеты $X_i$ для эмперического распределения $Y_i$ для таргет распределения и будем урезать бакеты $X_i$ до размеров бакетов $Y_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-03T12:41:06.373542Z",
     "iopub.status.busy": "2024-11-03T12:41:06.373102Z",
     "iopub.status.idle": "2024-11-03T12:41:06.388646Z",
     "shell.execute_reply": "2024-11-03T12:41:06.387376Z",
     "shell.execute_reply.started": "2024-11-03T12:41:06.373486Z"
    }
   },
   "outputs": [],
   "source": [
    "data = games_df[games_df['control'] == 'rapid']['length']\n",
    "\n",
    "data_with_noize = data.to_numpy() + np.random.uniform(0, 1, len(data))\n",
    "stats.kstest(data_with_soize, 'exponnorm', exponnorm.fit(data_with_soize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = exponnorm.rvs(*exponnorm.fit(data_with_soize), size=len(data_with_soize))\n",
    "\n",
    "def adjust_buckets(X, Y, n):\n",
    "    X = np.sort(X.copy())\n",
    "    Y = np.sort(Y.copy())\n",
    "\n",
    "    X_bins = np.array_split(X, n)\n",
    "    Y_bins = np.array_split(Y, n) \n",
    "    \n",
    "    X_out = []\n",
    "\n",
    "    for i in range(n):        \n",
    "        X_out.extend(\n",
    "            np.random.choice(X_bins[i], size=min(len(X_bins[i]), len(Y_bins[i])), replace=False)\n",
    "        )\n",
    "    return X_out\n",
    "\n",
    "mask_X = (data_with_noize > 65) & (data_with_noize < 80)\n",
    "mask_Y = (target > 65) & (target < 80)\n",
    "\n",
    "X_out = adjust_buckets(data_with_noize[mask_X], target[mask_Y], n=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_noize = data_with_noize[~mask_X].tolist() + X_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kstest(data_with_noize, 'exponnorm', exponnorm.fit(data_with_soize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(x=data_with_noize, opacity=0.2, nbins=300, histnorm='probability density')\n",
    "\n",
    "params = exponnorm.fit(data_with_noize)\n",
    "pdf = exponnorm.pdf(x_values, *params)\n",
    "fig.add_trace(go.Scatter(x=x_values, y=pdf, mode='lines', name=\"ExponNorm\"))\n",
    "\n",
    "fig.update_layout(title=\"Imperical pdf and fitted distrubution\")\n",
    "fig.show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все равно не работает, а большим макакингом заниматься я не хочу\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10033477,
     "datasetId": 5978579,
     "sourceId": 9789639,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
